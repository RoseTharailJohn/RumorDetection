{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import nltk as nltk\n",
      "import matplotlib as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_root = \"/home/rose/UMass/Courses/F15/NLP/Homeworks/PROJECT/RumorDetection/Data/Phase1/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_tweets_label(filepath) :\n",
      "    df = pd.read_csv(filepath,sep='\\t')\n",
      "    columns_of_interest = ['tweet','label']\n",
      "    df = df.reindex(columns=columns_of_interest)\n",
      "    df.loc[df['label'] > 0, 'label'] = 1\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load datafiles\n",
      "airfrance_raw = load_tweets_label(data_root+\"airfrance.txt\")\n",
      "michelle_raw = load_tweets_label(data_root+\"michelle.txt\")\n",
      "palin_raw = load_tweets_label(data_root+\"palin.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"PALIN DATASET : \", palin_raw.shape)\n",
      "print (\"MICHELLE DATASET : \", michelle_raw.shape)\n",
      "print (\"AIRFRANCE DATASET : \", airfrance_raw.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('PALIN DATASET : ', (4423, 2))\n",
        "('MICHELLE DATASET : ', (299, 2))\n",
        "('AIRFRANCE DATASET : ', (505, 2))\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#join the two dataframes\n",
      "michelle_airfrance_raw = michelle_raw.append(airfrance_raw)\n",
      "print (\"MICHELLE - AIRFRANCE DATASET : \", michelle_airfrance_raw.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('MICHELLE - AIRFRANCE DATASET : ', (804, 2))\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tokenization\n",
      "import re\n",
      " \n",
      "emoticons_str = r\"\"\"\n",
      "    (?:\n",
      "        [:=;] # Eyes\n",
      "        [oO\\-]? # Nose (optional)\n",
      "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
      "    )\"\"\"\n",
      " \n",
      "regex_str = [\n",
      "    emoticons_str,\n",
      "    r'<[^>]+>', # HTML tags\n",
      "    r'RT\\s*(?:@[\\w_]+)', # @-mentions\n",
      "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
      "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
      "    #r\"is\\s+(that|this|it)\\s+\\w*\\s*(real|rl|true)\", # is that | this etc.. real\n",
      "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
      "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
      "    r'(?:[\\w_]+)', # other words\n",
      "    r'(?:\\S)' # anything else\n",
      "]\n",
      "\n",
      "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
      "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
      " \n",
      "def tokenize(s):\n",
      "    return tokens_re.findall(s)\n",
      " \n",
      "def preprocess(s, lowercase=False):\n",
      "    tokens = tokenize(s)\n",
      "    if lowercase:\n",
      "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
      "    return tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#feature extraction\n",
      "#create empty array -- 7 columns - 1st 6 are features, 7th column is label\n",
      "# col 0- count of question marks\n",
      "# col 1- count of exclamation marks\n",
      "# col 2- count of hashtags\n",
      "# col 3- count of urls\n",
      "# col 4- count of @ symbols\n",
      "# col 5- count of question phrases\n",
      "def extract_features(dataset) :\n",
      "    num_of_tweets = dataset.shape[0]\n",
      "    num_of_features = 7\n",
      "    features = np.zeros((num_of_tweets, num_of_features))\n",
      "    for i in range(0, num_of_tweets) :\n",
      "        \n",
      "        tweet = dataset.iloc[i]['tweet']\n",
      "        label = dataset.iloc[i]['label']\n",
      "        \n",
      "        # set label column to tweets label\n",
      "        features[i][6] = label\n",
      "        \n",
      "        # set other features after tokenizing and counting through all of them\n",
      "        tweet_tokens = tk.preprocess(tweet)\n",
      "        for token in tweet_tokens:\n",
      "            # count num of question marks\n",
      "            if token=='?' :\n",
      "                features[i][0]+=1\n",
      "            # count num of exclamation marks\n",
      "            if token=='!' :\n",
      "                features[i][1]+=1\n",
      "            # count num of hashtags\n",
      "            if re.search( r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", token) :\n",
      "                features[i][2]+=1\n",
      "            # count num of urls\n",
      "            if re.search( r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', token) :\n",
      "                features[i][3]+=1\n",
      "            # count retweet\n",
      "            if re.search( r'RT\\s*(?:@[\\w_]+)', token) :\n",
      "                features[i][4]+=1\n",
      "        # count question phrases\n",
      "        # question phrase - is(that | this | it ) true\n",
      "        if(re.search( r\"is\\s+(that|this|it)\\s+\\w*\\s*(real|rl|true)\", tweet)):\n",
      "           features[i][5]+=1\n",
      "        # question phrase - really? real etc.. \n",
      "        if(re.search( r\"real(l|ll|lly|ly)*(\\?|\\!)+\", tweet)):\n",
      "           features[i][5]+=1\n",
      "        # tweet contains the word unconfirmed\n",
      "        if(re.search(r\"unconfirmed\", tweet)):\n",
      "           features[i][5]+=1\n",
      "        # question phrase - what?? or something similar\n",
      "        if(re.search(r\"wh[a]*t[?!][?1]*\", tweet)):\n",
      "           features[i][5]+=1\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extract_features(palin_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "array([[ 6.,  0.,  1., ...,  1.,  0.,  1.],\n",
        "       [ 0.,  0.,  0., ...,  3.,  0.,  1.],\n",
        "       [ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
        "       ..., \n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
        "       [ 1.,  1.,  0., ...,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.zeros((5,1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.save(\"a.npy\", a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## before adding question phrase\n",
      "tweet = \"lkjlkf 3#ljl @is RT @this fff RT@fing reall??\"\n",
      "preprocess(tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "['lkjlkf',\n",
        " '3',\n",
        " '#ljl',\n",
        " '@',\n",
        " 'is',\n",
        " 'RT @this',\n",
        " 'fff',\n",
        " 'RT@fing',\n",
        " 'reall',\n",
        " '?',\n",
        " '?']"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# after adding the question phrase to the regexes. -- not a good idea\n",
      "tweet = \"l\n",
      "kjlkf 3#ljl is this ffffing reall??\"\n",
      "preprocess(tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "[('lkjlkf', '', ''),\n",
        " ('3', '', ''),\n",
        " ('#ljl', '', ''),\n",
        " ('is this ffffing real', 'this', 'real'),\n",
        " ('l', '', ''),\n",
        " ('?', '', ''),\n",
        " ('?', '', '')]"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tweets about the rumor\n",
      "print michelle_raw[michelle_raw.label>0].sum()['label']\n",
      "print airfrance_raw[airfrance_raw.label>0].sum()['label']\n",
      "print palin_raw[palin_raw.label>0].sum()['label']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "216\n",
        "199\n",
        "4337"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Added by Yamin\n",
      "def load_tweets_label_boston(filepath) :\n",
      "\t#read the file\n",
      "    df = pd.read_csv(filepath,sep='\\t')\n",
      "    #extract only the tweet and label for now\n",
      "    columns_of_interest = ['rumor_cluster_id','label','tweet']\n",
      "    df = df.reindex(columns=columns_of_interest)\n",
      "    #we are interested in only if the tweet is a rumor or not - so, \n",
      "    #we give it two classes - 0 - for not rumor, 1 - for rumor\n",
      "    df.loc[df['label'] > 0, 'label'] = 1\n",
      "    return df\n",
      "\n",
      "boston_raw=load_tweets_label_boston(data_root+\"boston_baseline_raw\")\n",
      "print boston_raw[boston_raw.label>0].sum()['label']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "86\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f1 = np.load(data_root+\"train_palin_boston_nonrumors.npy\")\n",
      "f2 = np.load(data_root+\"test_michelle_cell_airfrance_obama.npy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_rumors = []\n",
      "train_nonrumors = []\n",
      "test_rumors = []\n",
      "test_nonrumors = []\n",
      "for i in range(f1.shape[0]) :\n",
      "    if f1[i][6]==0:\n",
      "        train_nonrumors.append(f1[i])\n",
      "    else:\n",
      "        train_rumors.append(f1[i])\n",
      "for i in range(f2.shape[0]) :\n",
      "    if f2[i][6]==0:\n",
      "        test_nonrumors.append(f2[i])\n",
      "    else:\n",
      "        test_rumors.append(f2[i])        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print( \"NO OF TRAIN NON RUMORS: \",len(train_nonrumors))\n",
      "print( \"NO OF TRAIN RUMORS: \",len(train_rumors))\n",
      "print( \"NO OF TEST NON RUMORS: \",len(test_nonrumors))\n",
      "print( \"NO OF TEST RUMORS: \",len(test_rumors))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('NO OF TRAIN NON RUMORS: ', 2439)\n",
        "('NO OF TRAIN RUMORS: ', 2439)\n",
        "('NO OF TEST NON RUMORS: ', 482)\n",
        "('NO OF TEST RUMORS: ', 549)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(train_nonrumors,axis=0)\n",
      "print np.sum(train_nonrumors,axis=0)\n",
      "print np.var(train_nonrumors,axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.12464125  0.15785158  0.8204182   0.35752358  0.20541205  0.07052071\n",
        "  0.        ]\n",
        "[  304.   385.  2001.   872.   501.   172.     0.]\n",
        "[ 0.74789219  0.33301646  1.88246953  0.36172179  0.16567797  0.07128759\n",
        "  0.        ]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(test_nonrumors,axis=0)\n",
      "print np.sum(test_nonrumors,axis=0)\n",
      "print np.var(test_nonrumors,axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.15560166  0.24481328  0.24688797  0.78423237  0.33195021  0.10373444\n",
        "  0.        ]\n",
        "[  75.  118.  119.  378.  160.   50.    0.]\n",
        "[ 0.27246862  0.48363492  1.02825795  0.19410823  0.31719495  0.10957112\n",
        "  0.        ]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(train_rumors,axis=0)\n",
      "print np.sum(train_rumors,axis=0)\n",
      "print np.var(train_nonrumors, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.31652317  0.23698237  0.30176302  0.84173842  0.43214432  0.43542435\n",
        "  1.        ]\n",
        "[  772.   578.   736.  2053.  1054.  1062.  2439.]\n",
        "[ 0.74789219  0.33301646  1.88246953  0.36172179  0.16567797  0.07128759\n",
        "  0.        ]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(test_rumors,axis=0)\n",
      "print np.sum(test_rumors,axis=0)\n",
      "print np.var(test_rumors,axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.22040073  0.28779599  0.32969035  0.78870674  0.45537341  0.27868852\n",
        "  1.        ]\n",
        "[ 121.  158.  181.  433.  250.  153.  549.]\n",
        "[ 0.3576166   0.54376727  0.8548744   0.23586518  0.35729808  0.29209591\n",
        "  0.        ]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for creating histograms of  \n",
      "# y axis - num of tweets\n",
      "# x axis - num of question marks\n",
      "train_nonrumors = np.asarray(train_nonrumors)\n",
      "train_rumors = np.asarray(train_rumors)\n",
      "test_nonrumors = np.asarray(test_nonrumors)\n",
      "test_rumors = np.asarray(test_rumors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_qmarks_rumors.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "(549,)"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "#question marks distribution for train set non rumors\n",
      "train_qmarks_nonrumors = train_nonrumors[:,2]\n",
      "max_num_of_train_nonrumors_qmarks = np.max(train_qmarks_nonrumors)\n",
      "\n",
      "train_qmarks_rumors = train_rumors[:,2]\n",
      "max_num_of_train_rumors_qmarks = np.max(train_qmarks_rumors)\n",
      "\n",
      "test_qmarks_nonrumors = test_nonrumors[:,2]\n",
      "max_num_of_test_nonrumors_qmarks = np.max(test_qmarks_nonrumors)\n",
      "\n",
      "test_qmarks_rumors = test_rumors[:,2]\n",
      "max_num_of_test_rumors_qmarks = np.max(test_qmarks_rumors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_num_of_train_nonrumors_qmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "16.0"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot each qmarks distribution\n",
      "\n",
      "his = np.histogram(train_qmarks_nonrumors, bins=range(1,9))\n",
      "fig, ax = plt.subplots()\n",
      "offset = .4\n",
      "plt.bar(his[1][1:],his[0])\n",
      "ax.set_xticks(his[1][1:] + offset)\n",
      "ax.set_xticklabels( ('1','2','3','4','5','6','7','8') )\n",
      "plt.xlabel('Num of Hashtags')\n",
      "plt.ylabel('Num of tweets')\n",
      "plt.title('Histogram of Hashtags in Training Non-Rumor tweets')\n",
      "plt.show()\n",
      "\n",
      "#plt.hist(train_qmarks_nonrumors, bins=np.arange(0, 6))\n",
      "#plt.xlabel('Num of Question marks')\n",
      "#plt.ylabel('Num of tweets')\n",
      "#plt.title('Histogram of Question marks in Training Non-Rumor tweets')\n",
      "#plt.show()\n",
      "#plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
      "#plt.axis([40, 160, 0, 0.03])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_num_of_train_rumors_qmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "9.0"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_num_of_train_rumors_qmarks = np.max(train_qmarks_rumors)\n",
      "print max_num_of_train_rumors_qmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9.0\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot each qmarks distribution for train rumors\n",
      "his = np.histogram(train_qmarks_rumors, bins=range(1,11))\n",
      "fig, ax = plt.subplots()\n",
      "offset = .4\n",
      "plt.bar(his[1][1:],his[0])\n",
      "ax.set_xticks(his[1][1:] + offset)\n",
      "ax.set_xticklabels( ('1', '2', '3','4','5','6','7','8','9') )\n",
      "plt.xlabel('Num of Hashtags mentions')\n",
      "plt.ylabel('Num of tweets')\n",
      "plt.title('Histogram of Hashtags mentions in Training Rumor tweets')\n",
      "plt.show()\n",
      "\n",
      "#plt.hist(train_qmarks_nonrumors, bins=np.arange(0, 6))\n",
      "#plt.xlabel('Num of Question marks')\n",
      "#plt.ylabel('Num of tweets')\n",
      "#plt.title('Histogram of Question marks in Training Non-Rumor tweets')\n",
      "#plt.show()\n",
      "#plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
      "#plt.axis([40, 160, 0, 0.03])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot each qmarks distribution for test non- rumors\n",
      "print max_num_of_test_nonrumors_qmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15.0\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot each qmarks distribution for test rumors\n",
      "his = np.histogram(test_qmarks_nonrumors, bins=range(1,10))\n",
      "fig, ax = plt.subplots()\n",
      "offset = .4\n",
      "plt.bar(his[1][1:],his[0])\n",
      "ax.set_xticks(his[1][1:] + offset)\n",
      "#ax.set_xticklabels( ('1', '2', '3','4','5','6','7','8','9','10','11','12','13','14','15','16') )\n",
      "ax.set_xticklabels( ('1', '2', '3','4','5','6','7','8','9') )\n",
      "plt.xlabel('Num of Hashtag mentions')\n",
      "plt.ylabel('Num of tweets')\n",
      "plt.title('Histogram of Hashtag mentions in Test Non Rumor tweets')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print max_num_of_test_rumors_qmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.0\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot each qmarks distribution for test rumors\n",
      "his = np.histogram(test_qmarks_rumors, bins=range(1,9))\n",
      "fig, ax = plt.subplots()\n",
      "offset = .4\n",
      "plt.bar(his[1][1:],his[0])\n",
      "ax.set_xticks(his[1][1:] + offset)\n",
      "ax.set_xticklabels( ( '1', '2', '3','4','5','6','7') )\n",
      "plt.xlabel('Num of Hashtag mentions')\n",
      "plt.ylabel('Num of tweets')\n",
      "plt.title('Histogram of Hashtag in Test Rumor tweets')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "f = open(data_root+'palin_reduced.txt', 'wt')\n",
      "writer = csv.writer(f, delimiter='\\t')\n",
      "writer.writerow(\"date\\tuserid\\ttweet\\tlabel\" )\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=\"jkljl\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "'jkljl'"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_root"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'/home/rose/UMass/Courses/F15/NLP/Homeworks/PROJECT/RumorDetection/Data/Phase1/'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}