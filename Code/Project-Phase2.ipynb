{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import nltk as nltk\n",
      "import matplotlib as plt\n",
      "import re\n",
      "from scipy.stats import entropy\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regex_str = [\n",
      "    r'<[^>]+>', # HTML tags\n",
      "    r'RT\\s*(?:@[\\w_]+)', #RT @-Retweets\n",
      "    r'(?:@[\\w_]+)', #@-mentions\n",
      "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
      "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
      "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
      "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
      "    r'(?:[\\w_]+)', # other words\n",
      "    r'(?:\\S)' # anything else\n",
      "]\n",
      "\n",
      "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
      " \n",
      "def tokenize(s):\n",
      "    return tokens_re.findall(s)\n",
      " \n",
      "def preprocess(s, lowercase=True):\n",
      "    tokens = tokenize(s)\n",
      "    if lowercase:\n",
      "        tokens = [token if tokens_re.search(token) else token.lower() for token in tokens]\n",
      "    return tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_signal_tweet(tweet) :\n",
      "    # count question phrases\n",
      "    # question phrase - is(that | this | it ) true\n",
      "    tweet=tweet.lower()\n",
      "    # question phrase - is(that | this | it ) true\n",
      "    if(re.search( r\"is\\s+(that|this|it)\\s+\\w*\\s*(real|rl|true)\", tweet)):\n",
      "        return True\n",
      "    # question phrase - omg, o my god, oh my god, oh my gawd\n",
      "    if(re.search( r\"(omg)|(o)(h)*\\s*(my)\\s*(god|gawd)\", tweet)):\n",
      "        return True\n",
      "    if(re.search( r\"(are|is)\\s*(true)\", tweet )):\n",
      "        return True\n",
      "    # question phrase - really? real etc..\n",
      "    if(re.search( r\"real(l|ll|lly|ly)*(\\?|\\!)+\", tweet)):\n",
      "       return True\n",
      "    # question phrase - what?? or something similar\n",
      "    if(re.search(r\"wh[a]*t[?!][?1]*\", tweet)):\n",
      "       return True\n",
      "    # question phrase - rumor?\n",
      "    if(re.search(r\"(rumor\\s*)(\\?)|(hoax)|(gossip)|(scandal)\", tweet)):\n",
      "       return True\n",
      "    # tweet contains the word unconfirmed or debunked\n",
      "    if(re.search(r\"(unconfirm)(ed)*\", tweet)) :\n",
      "       return True\n",
      "    if(re.search(r\"(debunk)(ed)*|(dismiss)(ed)*\", tweet)):\n",
      "       return True\n",
      "    # question phrase - truth or true\n",
      "    if(re.search(r\"(tru)(e|th)|(false)|(fake)\", tweet)):\n",
      "       return True\n",
      "    # question phrase - truth or true\n",
      "    if(re.search(r\"(den)(ial|y|ied|ies)|(plausible)\", tweet)):\n",
      "       return True\n",
      "    return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tweet1 = \"lkjlkf 3#ljl @is RT @this fff RT@fing reall??\"\n",
      "# tweet2 = \"oh wait! is this madness???\"\n",
      "# print is_signal_tweet(tweet2)\n",
      "# print preprocess(tweet2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False\n",
        "['oh', 'wait', '!', 'is', 'this', 'madness', '?', '?', '?']\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def partition_to_signal_and_ordinary(tweets_in_cluster):\n",
      "    signal_tweets = []\n",
      "    ordinary_tweets = []\n",
      "    for tweet in tweets_in_cluster:\n",
      "        if(is_signal_tweet(tweet)):\n",
      "           signal_tweets.append(tweet)\n",
      "        else :\n",
      "            ordinary_tweets.append(tweet)\n",
      "    return (signal_tweets,ordinary_tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_avg_tweet_len(tweets_list):\n",
      "    token_count=0\n",
      "    for tweet in tweets_list:\n",
      "        tokens = preprocess(tweet)\n",
      "        token_count+=len(tokens)\n",
      "    return (token_count/len(tweets_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tweet1 = \"lkjlkf 3#ljl @is RT @this fff RT@fing reall??\"\n",
      "# tweet2 = \"oh wait! is this madness???\"\n",
      "# a=[tweet1,tweet2]\n",
      "# get_avg_tweet_len(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "9.5"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#percentage of retweets in the tweet list\n",
      "def get_percentage_of_retweets(tweets_list):\n",
      "    retweets_count = 0\n",
      "    for tweet in tweets_list:\n",
      "        # count retweet\n",
      "        if re.search( r'RT\\s*(?:@[\\w_]+)', tweet) :\n",
      "            retweets_count+=1\n",
      "    return (retweets_count/len(tweets_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#a\n",
      "#get_percentage_of_retweets(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "lkjlkf 3#ljl @is RT @this fff RT@fing reall??\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "0.25"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_avg_url_count(tweets_list):\n",
      "    url_count=0\n",
      "    for tweet in tweets_list:\n",
      "        tokens = preprocess(tweet)\n",
      "        for token in tokens:\n",
      "            # count num of urls\n",
      "            if re.match( r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', token) :\n",
      "                url_count+=1\n",
      "    return (url_count/len(tweets_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a.append(\"http://kja.lkjl.com see here\")\n",
      "# get_avg_url_count(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "0.3333333333333333"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_avg_hashtag_count(tweets_list):\n",
      "    hashtag_count=0\n",
      "    for tweet in tweets_list:\n",
      "        tokens = preprocess(tweet)\n",
      "        for token in tokens:\n",
      "            # count num of urls\n",
      "            if re.match( r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", token) :\n",
      "                hashtag_count+=1\n",
      "    return (hashtag_count/len(tweets_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a = ['lkjlkf 3#ljl @is RT @this fff RT@fing reall??',\n",
      "#  'oh wait! is this madness???',\n",
      "#  'http://kja.lkjl.com see here',\n",
      "#  'kjkfja #kljlj kljklaf #kkljf']\n",
      "# get_avg_hashtag_count(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "0.75"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_avg_mention_count(tweets_list):\n",
      "    mention_count=0\n",
      "    for tweet in tweets_list:\n",
      "        tokens = preprocess(tweet)\n",
      "        for token in tokens:\n",
      "            # count num of urls\n",
      "            if re.match( r\"(?:@[\\w_]+)\", token) :\n",
      "                print token\n",
      "                mention_count+=1\n",
      "    return (mention_count/len(tweets_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get_avg_mention_count(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "@is\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.25"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def entropy_tweet(words_list):\n",
      "\n",
      "    words_len=len(words_list)\n",
      "    counts=defaultdict(float)\n",
      "\n",
      "    for w in words_list:\n",
      "        counts[w] +=1 #increment count of w word\n",
      "\n",
      "    for w in counts.keys():\n",
      "        counts[w] = float(counts[w]/words_len)#increment count of w word\n",
      "\n",
      "    word_freqDist=list(counts.values())\n",
      "\n",
      "    return entropy(word_freqDist)\n",
      "\n",
      "def entropy_ratio(signal_words_list,all_words_list):\n",
      "    return entropy_tweet(signal_words_list)/entropy_tweet(all_words_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_token_list(tweets_list):\n",
      "    token_list = []\n",
      "    for tweet in tweets_list:\n",
      "        token_list.append(preprocess(tweet))\n",
      "    return token_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_features_for_clusters(cluster_tweets_dict) :\n",
      "    features = np.zeros((len(cluster_tweets_dict.keys()), 13))\n",
      "    i=0\n",
      "    for cluster_id in cluster_tweets_dict.keys():\n",
      "        tweets_in_cluster = cluster_tweets_dict[cluster_id]\n",
      "        (signal_tweets, ordinary_tweets) = partition_to_signal_and_ordinary(tweets_in_cluster)\n",
      "        features[i][0] = len(signal_tweets)/len(tweets_in_cluster)\n",
      "        features[i][1] = entropy_ratio(get_token_list(signal_tweets), get_token_list(tweets_in_cluster))\n",
      "        features[i][2] = get_avg_tweet_len(signal_tweets)\n",
      "        features[i][3] = get_avg_tweet_len(tweets_in_cluster)\n",
      "        features[i][4] = features[i][2] / features[i][3]\n",
      "        features[i][5] = get_percentage_of_retweets(signal_tweets)\n",
      "        features[i][6] = get_percentage_of_retweets(tweets_in_cluster)\n",
      "        features[i][7] = get_avg_url_count(signal_tweets)\n",
      "        features[i][8] = get_avg_url_count(tweets_in_cluster)\n",
      "        features[i][9] = get_avg_hashtag_count(signal_tweets)\n",
      "        features[i][10] = get_avg_hashtag_count(tweets_in_cluster)\n",
      "        features[i][11] = get_avg_mention_count(signal_tweets)\n",
      "        features[i][12] = get_avg_mention_count(tweets_in_cluster)\n",
      "        i+=1\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.zeros((1,13))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}